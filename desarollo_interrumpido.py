# -*- coding: utf-8 -*-
"""Desarollo interrumpido.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lSj9J7qn1vR5YCENhws-RfDe_K01Ehn_
"""

from google.colab import drive
drive.mount('/content/drive')

#descargamos la base de datos y vemos sus caracteristicas
import pandas as pd
import numpy as np


# Reemplaza 'nombre_del_archivo.csv' con la ruta a tu archivo CSV
df = pd.read_csv('/content/drive/MyDrive/life expectancy.csv')
display(df.head())
print(df.info())
print(df.isna().sum())

#verificamos que los datos estén ordenados por país y año
df = df.sort_values(by=["Country Name", "Year"]).reset_index(drop=True)

#identificamos las columnas numéricas y categóricas
num_cols = df.select_dtypes(include=["float64", "int64"]).columns
cat_cols = df.select_dtypes(include=["object"]).columns

print("Numéricas:", list(num_cols))
print("Categóricas:", list(cat_cols))

!pip install wbgapi

"""
Necesitamos convertir región y  grupo de ingresos en variables numéricas,
codificando con un map

Además, Como vemos, hay muchos datos faltantes por lo que hay que limpiar e
impotar las variables que nos interesan.
"""
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
import wbgapi as wb
import pandas as pd

df_clean = df.copy()

# =============================================================================
# Limpieza
# =============================================================================
# Verificamos si un pais tiene muchos datos faltantes, si es el caso hay que
# imputar, de lo contrario se reduce la varianza y perdemos estimadores, por lo
# que es mejor eliminarlo.


umbral_nulos = 0.4
df_clean['nulos_fila'] = df_clean.isnull().mean(axis=1)
df_clean = df_clean[df_clean['nulos_fila'] < umbral_nulos].copy()
df_clean = df_clean.drop(columns=['nulos_fila'])

# Aplicar la limpieza de nombres de columna después de la filtración
# eliminamos mayusculas, espacios y caracteres especiales.
df_clean.columns = df_clean.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('%', '')

#eliminamos la variable de corrupción por datos faltantes
df_clean = df_clean.drop(columns=['corruption'])


# codificación de categóricas

mapa_ingresos = {
    'Low income': 1, # Cambiar a snake_case
    'Lower middle income': 2, # Cambiar a snake_case
    'Upper middle income': 3, # Cambiar a snake_case
    'High income': 4 # Cambiar a snake_case
}

df_clean['incomegroup_encoded'] = df_clean['incomegroup'].map(mapa_ingresos)

le = LabelEncoder()
df_clean['region_encoded'] = le.fit_transform(df_clean['region'])


# estandarización de las variables de salud

# descargamos la población para los años 2001-2009
df_pop_wdi = wb.data.DataFrame('SP.POP.TOTL', time=range(2001, 2020), labels=False)
df_pop_wdi = df_pop_wdi.reset_index().rename(columns={'economy': 'country_code'}) # Renombrado a 'country_code' para que coincida con df_clean
df_pop_long = df_pop_wdi.melt(id_vars='country_code', var_name='Year', value_name='Population')
df_pop_long['Year'] = df_pop_long['Year'].str.replace('YR', '').astype(int)

# Renombrar la columna 'Year' a 'year' en df_pop_long para que coincida con df_clean
df_pop_long = df_pop_long.rename(columns={'Year': 'year'})

print (df_pop_long.head())

df_est = pd.merge(df_clean, df_pop_long, on=['country_code', 'year'], how='left') # Cambiado 'Year' a 'year' aquí también

# Verificamos si hay nulos en población (países que no cruzaron bien)
print(f"Países sin población encontrada: {df_est['Population'].isna().sum()}")

# 3. Ahora sí, calculamos las tasas vectorizadamente (sin bucles for)
variables_abs = ['injuries', 'communicable', 'noncommunicable'] # Nombres de columnas en minúsculas después de la limpieza

for var in variables_abs:
    # Fórmula epidemiológica: (Casos / Pob) * 100,000
    df_est[f'{var}_rate'] = (df_est[var] / df_est['Population']) * 100000

    # Opcional: Borrar la columna absoluta original para evitar colinealidad
    # df_est.drop(columns=[var], inplace=True)


display(df_est.head())
print(df_est.info())
print(df_est.isna().sum())


# =============================================================================
# Imputación
# =============================================================================

cols_numericas = [
    'year', 'life_expectancy_world_bank', 'prevelance_of_undernourishment',
    'co2', 'health_expenditure_', 'education_expenditure_',
    'unemployment', 'sanitation', 'incomegroup_encoded', 'region_encoded',
    'injuries_rate','communicable_rate', 'noncommunicable_rate', 'Population'
]

# ninguna de estas variables es negativa pero algunas toman valores muy cercanos
# a cero, lo cual haria que el metodo asigne valores negativos a los imputados
minimos = [
    -np.inf, # year
    0,       # life_expectancy
    0,       # undernourishment
    0,       # co2
    0,       # health_expenditure
    0,       # education_expenditure
    0,       # unemployment
    0,       # sanitation (AQUÍ ESTÁ LA CLAVE)
    -np.inf, # incomegroup (lo arreglaremos con redondeo)
    -np.inf, # region
    0,       # injuries
    0,       # communicable
    0,       # noncommunicable
    0        # Population
]


#Imputador Iterativo (Usa BayesianRidge por defecto)
imputer = IterativeImputer(max_iter=10, random_state=0, min_value=minimos)

#el imputador aprende las relaciones entre variables para llenar los huecos
print("Iniciando imputación avanzada (esto puede tardar unos segundos)...")
matriz_imputada = imputer.fit_transform(df_est[cols_numericas])

#volcamos los datos imputados de regreso al DataFrame
df_imp = df_est.copy()
df_imp[cols_numericas] = matriz_imputada

#verificación final
print("\n¿Quedan nulos después de MICE?: ")
print(df_imp[cols_numericas].isnull().sum().sum())
display(df_imp.head())
print(df_imp.info())
print(df_imp.isna().sum())

"""
Veamos la regresión de la esperanza, nos ayudara a tener una primera intuición
de los datos.
"""

import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

#agrupamos por año y region
df_regional_avg = df_clean.groupby(['year', 'region'])['life_expectancy_world_bank'].mean().reset_index()

plt.figure(figsize=(14, 8))
regions = df_regional_avg['region'].unique()#obtener las regiones

# paleta de coloroes para que se vean más la diferencias
palette = sns.color_palette("muted", len(regions))

# grafica de dispersión y OLS para cada región
for i, region in enumerate(regions):
    df_region = df_regional_avg[df_regional_avg['region'] == region]
    sns.scatterplot(x='year', y='life_expectancy_world_bank', data=df_region,
                    color=palette[i], s=80, alpha=0.6, label=f'{region}')

    # OLS regression
    y = df_region['life_expectancy_world_bank']
    X = df_region['year']
    X_const = sm.add_constant(X)
    model = sm.OLS(y, X_const).fit()

    # Plot regression line
    plt.plot(df_region['year'], model.predict(X_const),
             color=palette[i],
             linewidth=2.5,
             linestyle='--',
             alpha=0.8)

plt.title('Esperanza de vida promedio en los años 2001-2019 por región',
          fontsize=14, fontweight='bold')
plt.xlabel('Year', fontsize=12)
plt.ylabel('Average Life Expectancy (years)', fontsize=12)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

for col in cols_numericas:
  plt.figure(figsize=(10, 5))
  sns.kdeplot(df_est[col], label='Original (con nulos)', fill=True, common_norm=False, alpha=0.5, linewidth=1)
  sns.kdeplot(df_imp[col], color ='#c4686e', label='Imputado (MICE)', lw=2, linestyle='--')
  plt.title(col)
  plt.legend()
  plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from scipy import stats

sns.set_theme(style="whitegrid", context="paper")

# Excluir las columnas especificadas de la lista de columnas numéricas a plotear
plot_cols = [col for col in cols_numericas if col not in ['year', 'incomegroup_encoded',
    'region_encoded', 'injuries_rate', 'communicable_rate', 'noncommunicable_rate']]

# Crear una figura de 2 filas x 4 columnas para 7 plots (dejando 1 vacío)
fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(10, 15), constrained_layout=True)
axes = axes.flatten() # Aplanar para iterar fácilmente

for i, col in enumerate(plot_cols):
    ax = axes[i]

    # A. Plot Datos Originales (Azul, relleno suave)
    sns.kdeplot(df_est[col], ax=ax, fill=True, color="#1f77b4", alpha=0.3,
                linewidth=2, label='Original (con nulos)')

    # B. Plot Datos Imputados (Rojo, línea discontinua para diferenciar)
    sns.kdeplot(df_imp[col], ax=ax, color="#d62728", linestyle="--",
                linewidth=2, label='Imputado (MICE)')

    # C. Estética
    ax.set_title(f'Distribución: {col}', fontweight='bold')
    ax.set_xlabel('')
    ax.set_ylabel('Densidad' if i % 4 == 0 else '') # Solo eje Y en la primera columna de cada fila

    # Solo poner leyenda en el primer gráfico para no ensuciar
    if i == 0:
        ax.legend(loc='upper left')
    else:
        if ax.get_legend(): ax.get_legend().remove()

# Ocultar ejes vacíos si hay menos columnas que subplots (en este caso, el último)
for j in range(len(plot_cols), len(axes)):
    fig.delaxes(axes[j])

plt.suptitle('Evaluación de Imputación Bayesiana: Comparativa de Distribuciones (Variables Seleccionadas)', fontsize=16, y=1.05)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

plt.figure(figsize=(12, 10))

variables = [
    'life_expectancy_world_bank', 'prevelance_of_undernourishment',
    'co2', 'health_expenditure_', 'education_expenditure_',
    'unemployment', 'sanitation', 'incomegroup_encoded', 'region_encoded',
    'injuries_rate', 'communicable_rate', 'noncommunicable_rate', 'Population'
]

# Corrected line: Select columns by name directly from the DataFrame
corr_matrix = df_imp[variables].corr()

# Definir el mapeo de nombres de columnas
nombre_columnas_map = {
    'life_expectancy_world_bank': 'Esperanza de vida',
    'prevelance_of_undernourishment': 'Desnutrición',
    'co2': 'CO2',
    'health_expenditure_': 'Gasto Salud',
    'education_expenditure_': 'Gasto Educación',
    'unemployment': 'Desempleo',
    'sanitation': 'Saneamiento',
    'incomegroup_encoded': 'Grupo Ingresos',
    'region_encoded': 'Región',
    'injuries_rate': 'Lesiones',
    'communicable_rate': 'Enf. Transmisibles',
    'noncommunicable_rate': 'Enf. No Transmisibles',
    'Population': 'Población'
}

# Renombrar las columnas de la matriz de correlación
corr_matrix_renamed = corr_matrix.rename(columns=nombre_columnas_map, index=nombre_columnas_map)

# Dibujamos el mapa de calor con los nombres renombrados y los números más grandes
sns.heatmap(corr_matrix_renamed, annot=True, cmap='vlag', fmt=".2f", annot_kws={"fontsize": 12}) # Ajusta el tamaño de la fuente aquí
plt.title("Mapa de Correlación: ¿Qué impacta la esperanza de vida?")
plt.show()

# yyy como le va a México?

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# filtrar los datos para México en df_imp
df_mexico = df_imp[df_imp['country_name'] == 'Mexico'].copy()

# definir las variables a graficar
variables_mexico = [
    'life_expectancy_world_bank',
    'prevelance_of_undernourishment',
    'co2',
    'health_expenditure_',
    'education_expenditure_',
    'unemployment',
    'sanitation',
    'injuries_rate',
    'communicable_rate',
    'noncommunicable_rate'
]

# graficar cada variable como una serie de tiempo
plt.figure(figsize=(15, 20))
for i, var in enumerate(variables_mexico):
    plt.subplot(len(variables_mexico), 1, i + 1) # Crear un subplot para cada variable
    sns.lineplot(x='year', y=var, data=df_mexico, marker='o')
    plt.title(f'Evolución de {var} en México (2001-2019)')
    plt.xlabel('Año')
    plt.ylabel(var)
    plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout() # Ajustar el diseño para evitar superposiciones
plt.show()

def plot_radar_robust(df, pais, anio_inicio, anio_fin, variables):
    # 1. Verificación de seguridad: ¿Existen las columnas?
    missing_cols = [c for c in variables if c not in df.columns]
    if missing_cols:
        print(f"ERROR: Las siguientes columnas no están en el DataFrame: {missing_cols}")
        return

    # 2. Filtrar datos del país
    datos = df[(df['country_name'] == pais) & (df['year'].isin([anio_inicio, anio_fin]))].copy()

    if len(datos) < 1: # Permitimos graficar aunque sea un solo año para ver qué hay
        print(f"No hay datos para {pais} en esos años.")
        return

    # 3. Normalización Robusta (Evita que Qatar o países en guerra aplasten tu gráfica)
    datos_norm = datos.copy()

    print(f"--- Valores Crudos para {pais} ---")
    for col in variables:
        # Usamos el percentil 95 como "Máximo lógico" y el 5 como "Mínimo lógico"
        # Esto elimina los outliers extremos del escalado
        max_val = df[col].quantile(0.95)
        min_val = df[col].quantile(0.05)

        # Evitar división por cero
        if max_val == min_val:
            max_val += 0.001

        # Normalizar y aplicar Clipping (para que no se salga del 0 al 1)
        datos_norm[col] = (datos[col] - min_val) / (max_val - min_val)
        datos_norm[col] = datos_norm[col].clip(0, 1) # Obliga a estar entre 0 y 1

        # DEBUG: Imprimir valores para asegurar que no son nulos
        val_inicio = datos[datos['year'] == anio_inicio][col].values
        val_fin = datos[datos['year'] == anio_fin][col].values
        print(f"{col}: {val_inicio} -> {val_fin} (Norm: {datos_norm[datos_norm['year'] == anio_fin][col].values})")

    # 4. Preparar Radar
    categories = variables
    N = len(categories)
    angles = [n / float(N) * 2 * np.pi for n in range(N)]
    angles += angles[:1] # Cerrar el círculo

    plt.figure(figsize=(10, 10))
    ax = plt.subplot(111, polar=True)

    # Ajustar el "Norte" del radar y la dirección
    ax.set_theta_offset(np.pi / 2)
    ax.set_theta_direction(-1)

    # Colores
    color_inicio = '#1f77b4' # Azul clásico
    color_fin = '#d62728'    # Rojo clásico

    # --- Plot Año Inicio ---
    if anio_inicio in datos_norm['year'].values:
        values1 = datos_norm[datos_norm['year'] == anio_inicio][categories].values.flatten().tolist()
        values1 += values1[:1]
        ax.plot(angles, values1, linewidth=2, linestyle='--', color=color_inicio, label=str(anio_inicio))
        ax.fill(angles, values1, color_inicio, alpha=0.1)

    # --- Plot Año Fin ---
    if anio_fin in datos_norm['year'].values:
        values2 = datos_norm[datos_norm['year'] == anio_fin][categories].values.flatten().tolist()
        values2 += values2[:1]
        ax.plot(angles, values2, linewidth=2, linestyle='solid', color=color_fin, label=str(anio_fin))
        ax.fill(angles, values2, color_fin, alpha=0.2)

    # Estética de los ejes
    plt.xticks(angles[:-1], categories, size=9)
    ax.set_rlabel_position(0)
    plt.yticks([0.25, 0.5, 0.75], ["Bajo", "Medio", "Alto"], color="grey", size=8)
    plt.ylim(0, 1)

    plt.title(f"Perfil de Evolución: {pais}\nComparativa Normalizada (Escala Robusta)", size=14, y=1.1)
    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))
    plt.show()

# Ejecutar
primer_anio = int(df_imp['year'].min())
ultimo_anio = int(df_imp['year'].max())

plot_radar_robust(df_imp, 'Mexico', primer_anio, ultimo_anio, variables_mexico)

indicadores = {
    'SP.DYN.LE00.IN': 'Esperanza_Vida',
    'SN.ITK.DEFC.ZS': 'Desnutricion',
    'EN.ATM.CO2E.PC': 'CO2_per_capita',
    'SH.XPD.CHEX.GD.ZS': 'Gasto_Salud_PIB',
    'SE.XPD.TOTL.GD.ZS': 'Gasto_Educacion_PIB',
    'SL.UEM.TOTL.ZS': 'Desempleo',
    'SH.STA.SMSS.ZS': 'Saneamiento',
    'VC.IHR.PSRC.P5': 'Homicidios_tasa',
    'SH.DTH.INJR.ZS': 'Muertes_Lesiones_pct',
    'SH.DTH.COMM.ZS': 'Muertes_Transmisibles_pct',
    'SH.DTH.NCOM.ZS': 'Muertes_NoTransmisibles_pct'
}

# descargar Serie de Tiempo
print("Descargando serie histórica para México...")
df_mex = wb.data.DataFrame(indicadores.keys(), economy=['MEX'], time=range(2000, 2023), numericTimeKeys=True)

# Limpieza

# Renombramos el índice (que contiene los códigos de los indicadores) a nombres amigables
df_mex = df_mex.rename(index=indicadores)
# Transponemos el DataFrame para que los años sean el índice y los indicadores sean las columnas
df_mex = df_mex.T
# Aseguramos que el nombre del índice sea 'Year'
df_mex.index.name = 'Year'

display(df_mex.head())


# Imputar

# Filtramos la lista 'var' para incluir solo las columnas presentes en df_mex
var = [col for col in indicadores.values() if col in df_mex.columns]

# Ajustamos la longitud de 'minimos' para que coincida con la cantidad de variables a imputar
minimos = [0] * len(var)


#Imputador Iterativo (Usa BayesianRidge por defecto)
imputer = IterativeImputer(max_iter=10, random_state=0, min_value=minimos)

#el imputador aprende las relaciones entre variables para llenar los huecos
print("Iniciando imputación avanzada (esto puede tardar unos segundos)...")
matriz_imputada = imputer.fit_transform(df_mex[var])

#volcamos los datos imputados de regreso al DataFrame
df_imp_mex = df_mex.copy() # Usamos el df_mex ya preprocesado
df_imp_mex[var] = matriz_imputada

#verificación final
print("\n¿Quedan nulos después de MICE?: ")
# Asegúrate de usar df_imp_mex en la verificación final
print(df_imp_mex[var].isnull().sum().sum())
display(df_imp_mex.head())
print(df_imp_mex.info())
print(df_imp_mex.isna().sum())

# forzamos a que todo sea numérico para evitar errores.
df_para_corr = df_imp_mex.apply(pd.to_numeric, errors='coerce')

print("Así se ve ahora (Variables en las columnas):")
display(df_para_corr.head())

plt.figure(figsize=(12, 10))
matriz_corr = df_para_corr.corr()

# Definir el mapeo de nombres de columnas
nombre_columnas_map = {
    'SP.DYN.LE00.IN': 'Esperanza_Vida',
    'SN.ITK.DEFC.ZS': 'Desnutricion',
    'EN.ATM.CO2E.PC': 'CO2_per_capita',
    'SH.XPD.CHEX.GD.ZS': 'Gasto_Salud_PIB',
    'SE.XPD.TOTL.GD.ZS': 'Gasto_Educacion_PIB',
    'SL.UEM.TOTL.ZS': 'Desempleo',
    'SH.STA.SMSS.ZS': 'Saneamiento',
    'VC.IHR.PSRC.P5': 'Homicidios_tasa', # Violencia
    # Usaremos las de % de muertes ya que las tasas absolutas requieren cálculo manual poblacional
    'SH.DTH.INJR.ZS': 'Muertes_Lesiones_pct',
    'SH.DTH.COMM.ZS': 'Muertes_Transmisibles_pct',
    'SH.DTH.NCOM.ZS': 'Muertes_NoTransmisibles_pct'
}

# Renombrar las columnas de la matriz de correlación
corr_renamed = matriz_corr.rename(columns=nombre_columnas_map, index=nombre_columnas_map)


sns.heatmap(corr_renamed, annot=True, cmap='vlag', fmt=".2f", vmin=-1, vmax=1)
plt.title("Mapa de Correlación: Variables en México (Histórico)")
plt.show()